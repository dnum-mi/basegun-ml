{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d0c0c41",
   "metadata": {},
   "source": [
    "# Compare the performances of a model in onnx mode or pth mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf27bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torch import Tensor\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.onnx\n",
    "import torchvision.models as Model\n",
    "from torchvision import transforms\n",
    "import onnx\n",
    "import onnxruntime\n",
    "from scipy.special import softmax\n",
    "from prepare_data import ConvertRgb, Rescale, RandomPad\n",
    "\n",
    "MODEL_NAME = 'EffB4'\n",
    "\n",
    "NETS = {\n",
    "    'EffB0': {'input_size': 224, 'model': Model.efficientnet_b0},\n",
    "    'EffB1': {'input_size': 240, 'model': Model.efficientnet_b1},\n",
    "    'EffB2': {'input_size': 288, 'model': Model.efficientnet_b2},\n",
    "    'EffB3': {'input_size': 300, 'model': Model.efficientnet_b3},\n",
    "    'EffB4': {'input_size': 380, 'model': Model.efficientnet_b4},\n",
    "    'EffB5': {'input_size': 456, 'model': Model.efficientnet_b5},\n",
    "    'EffB6': {'input_size': 528, 'model': Model.efficientnet_b6},\n",
    "    'EffB7': {'input_size': 600, 'model': Model.efficientnet_b7},\n",
    "    'Res18': {'input_size': 224, 'model': Model.resnet18},\n",
    "    'Dense169': {'input_size': 224, 'model': Model.densenet169},\n",
    "    'Dense201': {'input_size': 224, 'model': Model.densenet201}\n",
    "    }\n",
    "\n",
    "MODEL_TORCH = NETS[MODEL_NAME]['model']\n",
    "INPUT_SIZE = NETS[MODEL_NAME]['input_size']\n",
    "\n",
    "CLASSES = ['autre_epaule', 'autre_pistolet', 'epaule_a_levier_sous_garde',\n",
    "        'epaule_a_percussion_silex', 'epaule_a_pompe', 'epaule_a_un_coup', 'epaule_a_verrou',\n",
    "        'pistolet_a_percussion_silex', 'pistolet_semi_auto_moderne', 'revolver']\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81ae049",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader =  transforms.Compose([\n",
    "            ConvertRgb(),\n",
    "            Rescale(INPUT_SIZE),\n",
    "            RandomPad(INPUT_SIZE),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "def build_model(model: Model) -> Model:\n",
    "    # freeze first layers\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    # Parameters of newly constructed modules have requires_grad=True by default\n",
    "    num_ftrs = model.classifier[1].in_features\n",
    "    # to try later : add batch normalization and dropout\n",
    "    model.classifier[1] = torch.nn.Linear(num_ftrs, len(CLASSES))\n",
    "    model = model.to(device)\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_model_inference(state_dict_path: str) -> Model:\n",
    "    model = build_model(MODEL_TORCH())\n",
    "    # Initialize model with the pretrained weights\n",
    "    model.load_state_dict(torch.load(state_dict_path, map_location=device)['model_state_dict'])\n",
    "    model.to(device)\n",
    "    # set the model to inference mode\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "ort_session = onnxruntime.InferenceSession('models/EffB4_2022-03-02_08.onnx')\n",
    "model = load_model_inference('models/EffB4_2022-03-02_08.pth')\n",
    "\n",
    "\n",
    "def test_image(path):\n",
    "    im = Image.open(path)\n",
    "    image = loader(im).float()\n",
    "    image = image.unsqueeze(0).to(device)\n",
    "    # ort_inputs = {ort_session.get_inputs()[0].name: image.detach().cpu().numpy()}\n",
    "    # output = ort_session.run(None, ort_inputs)[0]\n",
    "    # probs = softmax(output, axis=1)[0]\n",
    "    output = model(image)\n",
    "    probs = torch.nn.functional.softmax(output, dim=1).detach().numpy()[0]\n",
    "    res = [(CLASSES[i], round(probs[i]*100,2)) for i in range(len(CLASSES))]\n",
    "    res.sort(key=lambda x:x[1], reverse=True)\n",
    "    # display(im.resize((300,int(300*im.size[1]/im.size[0])))) # display image in notebook\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71f8fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, glob, time\n",
    "\n",
    "def test_folder():\n",
    "    moy_time = 0\n",
    "    list_imgs = glob.glob(os.path.join(sys.argv[1], '*'))\n",
    "    for path in list_imgs:\n",
    "        t = time.time()\n",
    "        print(test_image(path)[0], time.time()-t)\n",
    "        moy_time += time.time()-t\n",
    "    print(\"Avg time = \", round(moy_time / len(list_imgs), 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e45ad6e-400c-4170-afd4-10ee08b56464",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddleocr import PaddleOCR,draw_ocr\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import pyiqa\n",
    "from fuzzysearch import find_near_matches\n",
    "import time\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "# Paddleocr supports Chinese, English, French, German, Korean and Japanese.\n",
    "# You can set the parameter `lang` as `ch`, `en`, `french`, `german`, `korean`, `japan`\n",
    "# to switch the language model in order.\n",
    "OCR=PaddleOCR(det_model_dir='C:/Users/aurelien.martinez/Documents/Basegun/3.OCR/PaddleModels/detection', rec_model_dir='C:/Users/aurelien.martinez/Documents/Basegun/3.OCR/PaddleModels/recognition', cls_model_dir='C:/Users/aurelien.martinez/Documents/Basegun/3.OCR/PaddleModels/classification', use_angle_cls=True,show_log = False) # need to run only once to download and load model into memory\n",
    "images=os.listdir(\"./ImagesIRC/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68036ca-28e4-4bfc-b248-476604fb1836",
   "metadata": {},
   "source": [
    "# inference on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "62c7a252-1d00-4129-97fe-e48a6c8c832d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(results):\n",
    "    \"\"\"extracts raw text from PaddleOCR output\n",
    "    Args:\n",
    "        results: raw result from PaddleOCR\n",
    "\n",
    "    Returns:\n",
    "        text: A string with the text extracted from the image\n",
    "    \"\"\"\n",
    "    text=\" \"\n",
    "    for result in results:\n",
    "        text=text+result[1][0]+\" \"\n",
    "    return text.lower()\n",
    "\n",
    "\n",
    "def is_in(word,phrase):\n",
    "    \"\"\"Check if a word is in a word using fuzzysearch algorithm for a tolerance error\n",
    "    Args:\n",
    "        word: word seek in the text\n",
    "        phrase: text to explore\n",
    "\n",
    "    Returns:\n",
    "        boolean: true if word is in phrase\n",
    "    \"\"\"\n",
    "    res=find_near_matches(word, phrase, max_l_dist=1)\n",
    "    return len(res)>0\n",
    "    \n",
    "def is_alarm_model(text):\n",
    "    \"\"\"determine if the text is from an alarm model weapon image using rules defined with weapon experts\n",
    "    Args:\n",
    "        text: string of the extract text\n",
    "\n",
    "    Returns:\n",
    "        boolean: true if the an alarm model is recognized\n",
    "    \"\"\"\n",
    "    #fuzzy search for words but exat value for model number\n",
    "    zoraki=[\"r2\", \"925\",\"92s\",\"906\",\"2906\",\"918\",\"9o6\",\"29o6\"]\n",
    "    \n",
    "    #Blow\n",
    "    if is_in(\"blow\",text):\n",
    "        if any(word in text for word in [\"f92\",\"c75\"]):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    #Zoraki\n",
    "    elif is_in(\"zoraki\",text):\n",
    "        if any(word in text for word in zoraki):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    elif is_in(\"kimar\",text):\n",
    "        if is_in(\"auto\",text):\n",
    "            if \"75\" in text:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        elif \"911\" in text:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    elif is_in(\"auto\",text):\n",
    "        if \"92\" in text:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    elif is_in(\"alarm\",text): #Sur ce type de modèle il arrive que le mot kimar soit remplacé par le logo\n",
    "            if any(is_in(word,text) for word in [\"competitive\",\"power\"]):\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "    \n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def is_pak(text):\n",
    "    \"\"\"determine if the text is from an alarm model weapon image with a PAK engraving\n",
    "    Args:\n",
    "        text: string of the extract text\n",
    "\n",
    "    Returns:\n",
    "        boolean: true if the PAK engraving is recognized\n",
    "    \"\"\"\n",
    "    if any(word in text for word in [\"pak \",\"p.a.k\",\"pak.\",\" pak\",\"pa.k\",\"p.ak\"]):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def quality_eval(img):\n",
    "    \"\"\"Evaluate the CNNIQA for image quality and compare it to a defined threshold\n",
    "    Args:\n",
    "        img: PIL image\n",
    "\n",
    "    Returns:\n",
    "        boolean: true if the image has a good quality (score<threshold)\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cpu\")\n",
    "    metric = pyiqa.create_metric('cnniqa', device=device)\n",
    "    res=metric(img)\n",
    "    print(res)\n",
    "    return res>QUALITY_THRESHOLD\n",
    "\n",
    "\n",
    "def is_alarm_weapon(image_bytes):\n",
    "    \"\"\"Global pipeline for determining if the weapon is an alarm gun using OCR\n",
    "    Args:\n",
    "        image_bytes: Bytes image from Basegun\n",
    "\n",
    "    Returns:\n",
    "        string: User feedback on image quality or on alarm gun assessment\n",
    "    \"\"\"\n",
    "    img = Image.open(io.BytesIO(image_bytes))\n",
    "\n",
    "    if quality_eval(img):\n",
    "        results = model_ocr.ocr(np.asarray(img), cls=True)\n",
    "        print(results)\n",
    "        if results!=[None]: #The results with recongition and detection confidence below 0.5 are filtered by paddle, the thresholds values can be changed\n",
    "            text=get_text(results)\n",
    "            if is_alarm_model(text):\n",
    "                return \"alarm weapon from model\"\n",
    "            elif is_pak(text):\n",
    "                return \"alarm weapon PAK\"\n",
    "            else:\n",
    "                return \"Not an alarm weapon\"\n",
    "        else:\n",
    "            return \"Text not detected please get closer to the weapon\"\n",
    "    else:\n",
    "        return \"The photo does not seem to have a good quality please take another photo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a491b4bb-039e-4fe0-b58e-8847b67b6d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dict={}\n",
    "device = torch.device(\"cpu\")\n",
    "metric = pyiqa.create_metric('cnniqa', device=device)\n",
    "for image in images:\n",
    "    img = Image.open(\"./ImagesIRC/\"+image)\n",
    "    width, height = img.size\n",
    "    ratio = 640/width\n",
    "    newsize = (640, int(height*ratio))\n",
    "    newsize2 = (1280, 2*int(height*ratio))\n",
    "    im1 = img.resize(newsize)\n",
    "    im2=img.resize(newsize2)\n",
    "    a=time.time()\n",
    "    quality= metric(im1)\n",
    "    result = OCR.ocr(\"./ImagesIRC/\"+image, cls=True)\n",
    "    if result[0]==None:\n",
    "        raw_text=\"\"\n",
    "        PAK = False\n",
    "        alarm_model=False\n",
    "    else:\n",
    "        raw_text=get_text(result[0])\n",
    "        PAK = is_pak(raw_text)\n",
    "        alarm_model=is_alarm_model(raw_text)\n",
    "    print(time.time()-a)\n",
    "    dict[image]={\"quality\":quality,\"result\":result,\"text\":raw_text,\"PAK_pred\":PAK,\"AlarmModel_pred\":alarm_model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d0561c-41ae-4bb5-a102-d982b3cf7593",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "feedf899-7691-4c16-84a0-d6f6471448db",
   "metadata": {},
   "source": [
    "# Preprocessing labelstudio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6e571036-e31b-4c1b-a213-1e53469f586f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c61ab78d-4c6a-4d6f-87fe-67647a6d9957",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('labels.csv')\n",
    "df.replace(np.nan, '', inplace=True)\n",
    "df['PAK'] = df['Arme Alarme'].apply(lambda x: 'PAK' in x)\n",
    "df['AlarmModel'] = df['Arme Alarme'].apply(lambda x: 'Arme' in x)\n",
    "df['VueGlobale'] = df['Analyse image'].apply(lambda x: 'Globale' in x)\n",
    "df['Lisible'] = df['Analyse image'].apply(lambda x: 'Lisible' in x)\n",
    "\n",
    "l = ['Lisible,','Lisible','Vue Globale,','Vue Globale']\n",
    "\n",
    "\n",
    "df['TypeMarquage']=df['Analyse image'].apply(lambda x: x.split( ','))\n",
    "\n",
    "df['TypeMarquage'].apply(lambda x: x.remove('Lisible') if 'Lisible' in x else x)\n",
    "\n",
    "df['TypeMarquage'].apply(lambda x: x.remove('Vue Globale') if 'Vue Globale' in x else x)\n",
    "\n",
    "df.drop(columns=['Arme Alarme', 'info','Analyse image'],inplace=True)\n",
    "df.set_index('image', inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6ab87d-f338-4c7f-af84-82e2df30b79a",
   "metadata": {},
   "source": [
    "# Comparaison des resultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ee8b690b-48fe-4292-9c5a-5ff4671a777d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "79693f69-8767-4217-8757-f6333700c367",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred= pd.DataFrame(dict)\n",
    "pred=pred.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1054eb4a-4750-4c2a-9499-8bcd226dac5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison=labels.merge(pred,left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec9177c-f367-4fea-acf3-3149debe6a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331885de-a63d-4382-88b6-eb84769c5597",
   "metadata": {},
   "source": [
    "## Metrics on all dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbf3a9a-62dd-4d09-a915-b02111492530",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precisionPAK(df):\n",
    "    return len(df[(df['PAK']==df['PAK_pred']) & (df['PAK']==True)])/len(df[(df['PAK_pred']==True)])\n",
    "\n",
    "def precisionModel(df):\n",
    "    return len(df[(df['AlarmModel']==df['AlarmModel_pred']) & (df['AlarmModel']==True)])/len(df[(df['AlarmModel_pred']==True)])\n",
    "\n",
    "print(precisionPAK(comparison))\n",
    "print(precisionModel(comparison))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a58d0d9a-b34a-4d7e-8898-5dba210cf6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_graphPAK(df):\n",
    "    print(len(df[(df['PAK']==True)]))\n",
    "    print(len(df[(df['PAK']==df['PAK_pred']) & (df['PAK']==True)]))\n",
    "    print(len(df[(df['PAK']==False)]))\n",
    "    print(len(df[(df['PAK_pred']==True) & (df['PAK']==False)]))\n",
    "\n",
    "def value_graphModel(df):\n",
    "    print(len(df[(df['AlarmModel']==True)]))\n",
    "    print(len(df[(df['AlarmModel']==df['AlarmModel_pred']) & (df['AlarmModel']==True)]))\n",
    "    print(len(df[(df['AlarmModel']==False)]))\n",
    "    print(len(df[(df['AlarmModel_pred']==True) & (df['AlarmModel']==False)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b9e810-c28a-4859-b8e2-947ad23b2e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_graphModel(comparison[(comparison['VueGlobale']==False)])\n",
    "value_graphPAK(comparison[(comparison['VueGlobale']==False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f51bc8-7ed9-41be-a689-dd3972f2cc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recallPAK(df):\n",
    "    return len(df[(df['PAK']==df['PAK_pred']) & (df['PAK']==True)])/len(df[(df['PAK']==True)])\n",
    "\n",
    "def recallModel(df):\n",
    "    return len(df[(df['AlarmModel']==df['AlarmModel_pred']) & (df['AlarmModel']==True)])/len(df[(df['AlarmModel']==True)])\n",
    "\n",
    "print(recallPAK((comparison)))\n",
    "print(recallModel(comparison))\n",
    "len(comparison[(comparison['VueGlobale']==False)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c5e3c0-e027-40c2-b10f-6bf638e5b392",
   "metadata": {},
   "source": [
    "## Metrics on images with enough quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebbb8ea-c660-462a-ac90-1c08290c0397",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparisonQuality=comparison[(comparison['quality']>0.50)]\n",
    "print(len(comparisonQuality))\n",
    "\n",
    "print(precisionPAK(comparisonQuality))\n",
    "print(precisionModel(comparisonQuality))\n",
    "\n",
    "print(recallPAK(comparisonQuality))\n",
    "print(recallModel(comparisonQuality))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f33305-4bac-4263-8a4f-308d996bfb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_graphModel(comparisonQuality)\n",
    "value_graphPAK(comparisonQuality)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e1d7c0-1917-4c83-a673-9db3cb7a6a2c",
   "metadata": {},
   "source": [
    "## Metrics on images with enough quality and lisible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500c828f-6743-434c-accb-fb80ec8f7eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparisonQualityLisible=comparison[(comparison['quality']>0.50) & (comparison['Lisible'])]\n",
    "print(len(comparisonQualityLisible))\n",
    "\n",
    "print(precisionPAK(comparisonQualityLisible))\n",
    "print(precisionModel(comparisonQualityLisible))\n",
    "\n",
    "print(recallPAK(comparisonQualityLisible))\n",
    "print(recallModel(comparisonQualityLisible))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7109a0d-ff4a-4098-844a-b3d220012faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_graphModel(comparisonQualityLisible[comparisonQualityLisible['VueGlobale']==False])\n",
    "value_graphPAK(comparisonQualityLisible[comparisonQualityLisible['VueGlobale']==False])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6477f652-d096-4d99-860c-f00cf5da6b11",
   "metadata": {},
   "source": [
    "## Metrics on images with enough quality and lisible et vue rapprochée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2187eb-f7a6-4180-b01e-0c7d23ec4d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparisonQualityLisible=comparison[(comparison['quality']>0.50) & (comparison['Lisible'])&(comparison['VueGlobale']==False)]\n",
    "print(len(comparisonQualityLisible))\n",
    "\n",
    "print(precisionPAK(comparisonQualityLisible))\n",
    "print(precisionModel(comparisonQualityLisible))\n",
    "\n",
    "print(recallPAK(comparisonQualityLisible))\n",
    "print(recallModel(comparisonQualityLisible))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623b741f-dfff-456e-aa7e-07f881e3d0a0",
   "metadata": {},
   "source": [
    "## Metrics on images with enough quality and lisible et vue rapprochée par type de marquage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459f06b8-156f-4dd8-8929-0e1ebbb94ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparisonQualityLisible2=comparison[(comparison['quality']>0.50) & (comparison['Lisible'])&(comparison['VueGlobale']==False)]\n",
    "\n",
    "comparisonQualityLisible2['TypeMarquage2']=comparisonQualityLisible2['TypeMarquage'].apply(lambda x: x[0] if len(x)>0 else '')\n",
    "comparisonQualityLisible2=comparisonQualityLisible2[comparisonQualityLisible2[\"TypeMarquage2\"]==\"Gravure\"]\n",
    "print(len(comparisonQualityLisible2))\n",
    "\n",
    "print(precisionPAK(comparisonQualityLisible2))\n",
    "print(precisionModel(comparisonQualityLisible2))\n",
    "\n",
    "print(recallPAK(comparisonQualityLisible2))\n",
    "print(recallModel(comparisonQualityLisible2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c93a36",
   "metadata": {},
   "source": [
    "# Identification du type d'erreurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0cae5f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAK_not_detected=comparisonQualityLisible[(comparisonQualityLisible['PAK']!=comparisonQualityLisible['PAK_pred']) & (comparisonQualityLisible['PAK']==True)&(comparison['VueGlobale']==False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b9d8c1bd-f6ee-4d6d-8d2a-b05811236ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "images=list(PAK_not_detected.index)\n",
    "labels=list(PAK_not_detected['text'])\n",
    "quality=list(PAK_not_detected['quality'])\n",
    "i=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc3fb82-9368-4921-a27e-ae92cb54d33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dd6191-d294-4ade-9b99-02ee822ce615",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img = Image.open(\"./ImagesIRC/\"+images[i])\n",
    "print(labels[i],quality[i])\n",
    "display(img)\n",
    "i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "6fd3b89c-e1f9-4cfd-ad8f-cab74c77ccb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_not_detected=comparisonQualityLisible[(comparisonQualityLisible['AlarmModel_pred']==False) & (comparisonQualityLisible['AlarmModel']==True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "8f2c558d-f484-4b83-87b5-232a6acf1118",
   "metadata": {},
   "outputs": [],
   "source": [
    "images=list(Model_not_detected.index)\n",
    "labels=list(Model_not_detected['text'])\n",
    "quality=list(Model_not_detected['quality'])\n",
    "i=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3191cf3-fb08-4076-bb61-3fea2e3bc464",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b20576-2e22-4584-8913-e8188f785174",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "img = Image.open(\"./ImagesIRC/\"+images[i])\n",
    "print(labels[i],quality[i])\n",
    "display(img)\n",
    "i=i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9248af3-7936-446a-97b1-e9e589ec37fe",
   "metadata": {},
   "source": [
    "# Statistiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "5095c92d-274b-4283-a2f4-526595db1ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=labels\n",
    "df['TypeMarquage2']=df['TypeMarquage'].apply(lambda x: x[0] if len(x)>0 else '')\n",
    "df=df.groupby('TypeMarquage2').size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3366b295-0ba0-48bc-9206-2cc1ae0d45dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

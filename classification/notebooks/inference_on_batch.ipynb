{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab7d390c",
   "metadata": {},
   "source": [
    "# Inference on batch\n",
    "Helper code to test a model on batch of images. We keep track of the results of prediction/inference in a csv (Metrics part) then we can chose to display examples of images were mistaken for another class. This way we can try to see patterns in why some images are incorrectly classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caca8cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "from torch import Tensor\n",
    "from seaborn import heatmap\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as Model\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from prepare_data import load_dataset, get_classes, get_dataloader, load_custom_dataset\n",
    "\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b0fa59",
   "metadata": {},
   "source": [
    "# Dataset with subfolders for classes\n",
    "\n",
    "## Metrics part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2ae03bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = 'data/train' # a changer selon les images à tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3325ad6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2\n",
    "\n",
    "EFFICIENTNETS = {\n",
    "    'B0': 224, 'B1': 240,\n",
    "    'B2': 288, 'B3': 300,\n",
    "    'B4': 380, 'B5': 456,\n",
    "    'B6': 528, 'B7': 600\n",
    "    }\n",
    "\n",
    "MODEL_NAME = 'B5'\n",
    "MODEL_TORCH = Model.efficientnet_b5\n",
    "INPUT_SIZE = EFFICIENTNETS[MODEL_NAME]\n",
    "\n",
    "dataset = load_dataset(DATA, input_size=INPUT_SIZE)\n",
    "classes = get_classes(dataset)\n",
    "dataloader = get_dataloader(dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d820468d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_metrics_model(model: Model, output_folder: str) -> None:\n",
    "    \"\"\" Computes metrics to evaluate model\n",
    "        Prints: accuracy, precision, recall\n",
    "        Writes: confusion matrix\n",
    "\n",
    "    Args:\n",
    "        model (Model): torch model to evaluate\n",
    "        training_name (str): id l'entraînement\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    prefix = '-'.join(DATA.split('/')) + '-' + datetime.now().isoformat(\"_\", \"minutes\")\n",
    "\n",
    "    # Initialize the prediction and label lists(tensors)\n",
    "    predlist=torch.zeros(0,dtype=torch.long, device='cpu')\n",
    "    lbllist=torch.zeros(0,dtype=torch.long, device='cpu')\n",
    "    outputlist=torch.zeros(0,dtype=torch.long, device='cpu')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloader):\n",
    "            if i%100==0:\n",
    "                print(f'Batch {i}/{len(dataloader)}, time : {round(time.time()-start, 2)} secs')\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            # Append batch prediction results\n",
    "            predlist=torch.cat([predlist,preds.view(-1).cpu()])\n",
    "            lbllist=torch.cat([lbllist,labels.view(-1).cpu()])\n",
    "            outputlist=torch.cat([outputlist,torch.nn.functional.softmax(outputs, dim=1).cpu().detach()])\n",
    "\n",
    "    # Confusion matrix\n",
    "    y_test, y_pred = lbllist.numpy(), predlist.numpy()\n",
    "    cm = confusion_matrix(y_test, y_pred, normalize='true')\n",
    "    df_cm = pd.DataFrame(cm, index = [i for i in classes], columns = [i for i in classes])\n",
    "    df_cm.to_csv(f'{output_folder}/{prefix}-confusion-matrix.csv') # visualize with sn heatmap\n",
    "\n",
    "    # Other scores\n",
    "    acc = accuracy_score(y_test, y_pred, normalize=True)\n",
    "    prec = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    with open(f'{output_folder}/{prefix}-details.txt', 'w') as outfile:\n",
    "        outfile.write(f'Accuracy = {round(acc, 3)}\\n')\n",
    "        outfile.write(f'Precision = {round(prec, 3)}\\n')\n",
    "        outfile.write(f'Recall = {round(rec, 3)}\\n')\n",
    "\n",
    "    # Details of predictions probabilities\n",
    "    probas = outputlist.numpy().transpose() # each line is the probas for this class\n",
    "    all_lines = {'filename': [x[0] for x in dataset.imgs],\n",
    "                'label': [classes[x[1]] for x in dataset.imgs],\n",
    "                'max_pred': [classes[x] for x in y_pred]}\n",
    "    for i in range(len(classes)):\n",
    "        all_lines[classes[i]] = probas[i]\n",
    "    df_prob = pd.DataFrame(all_lines)\n",
    "    df_prob.to_csv(f'{output_folder}/{prefix}-probas.csv', index=False)\n",
    "    print('FINISHED !!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7babe351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(model: Model) -> Model:\n",
    "    # freeze first layers\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    # Parameters of newly constructed modules have requires_grad=True by default\n",
    "    num_ftrs = model.classifier[1].in_features\n",
    "    # to try later : add batch normalization and dropout\n",
    "    model.classifier[1] = nn.Linear(num_ftrs, len(classes))\n",
    "    model = model.to(device)\n",
    "    return model\n",
    "\n",
    "def load_model_inference(state_dict_path: str):\n",
    "    model = build_model(MODEL_TORCH())\n",
    "    # Initialize model with the pretrained weights\n",
    "    model.load_state_dict(torch.load(state_dict_path, map_location=torch.device('cpu'))['model_state_dict']) # pour B5_2022-02-09_13 rajouter ['model_state_dict'] avant derniere parenthese\n",
    "    model.to(device)\n",
    "    # set the model to inference mode\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b28d459d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model_inference('models/B5_2022-02-09_13/B5_2022-02-09_13.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce3b339",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_metrics_model(model, 'B5_2022-02-09_13-on-dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb70a63",
   "metadata": {},
   "source": [
    "## Visualisation part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5f2ba9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prepare_data_tests import ConvertRgb, Rescale, RandomPad\n",
    "\n",
    "loader =  transforms.Compose([\n",
    "            ConvertRgb(),\n",
    "            Rescale(456),\n",
    "            RandomPad(456),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "def test_image(model, path):\n",
    "    t = time.time()\n",
    "    im = Image.open(path)\n",
    "    image = loader(im).float()\n",
    "    image = image.unsqueeze(0).to(device)\n",
    "    output = model(image)\n",
    "    probs = nn.functional.softmax(output, dim=1).detach().numpy()[0]\n",
    "    res = [(classes[i], round(probs[i]*100,2)) for i in range(len(classes))]\n",
    "    res.sort(key=lambda x:x[1], reverse=True)\n",
    "    display(im.resize((300,int(300*im.size[1]/im.size[0])))) # display image in notebook\n",
    "    return res, f'Time : {round(time.time()-t, 3)} secs'\n",
    "\n",
    "\n",
    "def show_confusion_matrix(matrix_path: str):\n",
    "    df = pd.read_csv(matrix_path, index_col=0)\n",
    "    fig, ax = plt.subplots(figsize=(10,8))\n",
    "    heatmap(df, annot=True)\n",
    "\n",
    "\n",
    "def show_images_of_label_predicted_as(in_df: pd.DataFrame, true_label: str, pred_label: str, limit=20):\n",
    "    df = in_df[(in_df.label==true_label) & (in_df.max_pred==pred_label)]\n",
    "    df = df.sort_values(by=pred_label, ascending=False)\n",
    "    df = df.reset_index()\n",
    "    print(len(df), 'images found')\n",
    "\n",
    "    columns = 1\n",
    "    plt.figure(figsize=(80,600))\n",
    "    for index, row in df.head(limit).iterrows():\n",
    "        path = row['filename']\n",
    "        im = Image.open(path)\n",
    "        plt.subplot(len(df) / columns + 1, columns, index + 1).set_title(round(row[pred_label],3))\n",
    "        plt.axis('off')\n",
    "        plt.imshow(np.asarray(im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccc23da",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image(model, 'test/spas12.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d07403",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('B5_2022-02-07-on-dataset/data-val2022-02-14_10:48-probas.csv')\n",
    "show_images_of_label_predicted_as(df, 'autre_pistolet', 'pistolet_semi_auto_moderne')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59130289",
   "metadata": {},
   "source": [
    "# Single folder dataset\n",
    "\n",
    "## Metrics part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6ddd1833",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = 'data/val/epaule_a_mecanisme_ancien' # a changer selon les images à tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d57cdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2\n",
    "\n",
    "EFFICIENTNETS = {\n",
    "    'B0': 224, 'B1': 240,\n",
    "    'B2': 288, 'B3': 300,\n",
    "    'B4': 380, 'B5': 456,\n",
    "    'B6': 528, 'B7': 600\n",
    "    }\n",
    "\n",
    "MODEL_NAME = 'B5'\n",
    "MODEL_TORCH = Model.efficientnet_b5\n",
    "INPUT_SIZE = EFFICIENTNETS[MODEL_NAME]\n",
    "\n",
    "\n",
    "classes = ['autre_epaule', 'autre_pistolet', 'epaule_a_levier_sous_garde',\n",
    "        'epaule_a_percussion_silex', 'epaule_a_pompe', 'epaule_a_un_coup', 'epaule_a_verrou',\n",
    "        'pistolet_a_percussion_silex', 'pistolet_semi_auto_moderne', 'revolver']\n",
    "dataset = load_custom_dataset(input_size=INPUT_SIZE, folder=DATA)\n",
    "dataloader = get_dataloader(dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be2f082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_metrics_model(model: Model, output_folder: str) -> None:\n",
    "    \"\"\" Computes metrics to evaluate model\n",
    "        Prints: accuracy, precision, recall\n",
    "        Writes: confusion matrix\n",
    "\n",
    "    Args:\n",
    "        model (Model): torch model to evaluate\n",
    "        training_name (str): id l'entraînement\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    prefix = '-'.join(DATA.split('/')) + '-' + datetime.now().isoformat(\"_\", \"minutes\")\n",
    "\n",
    "    # Initialize the prediction and label lists(tensors)\n",
    "    predlist=torch.zeros(0,dtype=torch.long, device='cpu')\n",
    "    outputlist=torch.zeros(0,dtype=torch.long, device='cpu')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, inputs in enumerate(dataloader):\n",
    "            if i%100==0:\n",
    "                print(f'Batch {i}/{len(dataloader)}, time : {round(time.time()-start, 2)} secs')\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            # Append batch prediction results\n",
    "            predlist=torch.cat([predlist,preds.view(-1).cpu()])\n",
    "            outputlist=torch.cat([outputlist,torch.nn.functional.softmax(outputs, dim=1).cpu().detach()])\n",
    "\n",
    "    # Details of predictions probabilities\n",
    "    y_pred = predlist.numpy()\n",
    "    probas = outputlist.numpy().transpose() # each line is the probas for this class\n",
    "    all_lines = {'filename': [x for x in dataset.imgs],\n",
    "                'max_pred': [classes[x] for x in y_pred]}\n",
    "    for i in range(len(classes)):\n",
    "        all_lines[classes[i]] = probas[i]\n",
    "    df_prob = pd.DataFrame(all_lines)\n",
    "    df_prob.to_csv(f'{output_folder}/{prefix}-probas.csv', index=False)\n",
    "    print('FINISHED !!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef16591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(model: Model) -> Model:\n",
    "    # freeze first layers\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    # Parameters of newly constructed modules have requires_grad=True by default\n",
    "    num_ftrs = model.classifier[1].in_features\n",
    "    # to try later : add batch normalization and dropout\n",
    "    model.classifier[1] = nn.Linear(num_ftrs, len(classes))\n",
    "    model = model.to(device)\n",
    "    return model\n",
    "\n",
    "def load_model_inference(state_dict_path: str):\n",
    "    model = build_model(MODEL_TORCH())\n",
    "    # Initialize model with the pretrained weights\n",
    "    model.load_state_dict(torch.load(state_dict_path, map_location=torch.device('cpu'))) # pour B5_2022-02-09_13 rajouter ['model_state_dict'] avant derniere parenthese\n",
    "    model.to(device)\n",
    "    # set the model to inference mode\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ed7630",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model_inference('models/B5_2022-02-07/B5_2022-02-07.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26898295",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_metrics_model(model, 'B5_2022-02-07-on-dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbd81ca",
   "metadata": {},
   "source": [
    "## Visualisation part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1587f6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prepare_data_tests import ConvertRgb, Rescale, RandomPad\n",
    "\n",
    "loader =  transforms.Compose([\n",
    "            ConvertRgb(),\n",
    "            Rescale(456),\n",
    "            RandomPad(456),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "def test_image(model, path):\n",
    "    t = time.time()\n",
    "    im = Image.open(path)\n",
    "    image = loader(im).float()\n",
    "    image = image.unsqueeze(0).to(device)\n",
    "    output = model(image)\n",
    "    probs = nn.functional.softmax(output, dim=1).detach().numpy()[0]\n",
    "    res = [(classes[i], round(probs[i]*100,2)) for i in range(len(classes))]\n",
    "    res.sort(key=lambda x:x[1], reverse=True)\n",
    "    display(im.resize((300,int(300*im.size[1]/im.size[0])))) # display image in notebook\n",
    "    return res, f'Time : {round(time.time()-t, 3)} secs'\n",
    "\n",
    "\n",
    "def show_confusion_matrix(matrix_path: str):\n",
    "    df = pd.read_csv(matrix_path, index_col=0)\n",
    "    fig, ax = plt.subplots(figsize=(10,8))\n",
    "    heatmap(df, annot=True)\n",
    "\n",
    "\n",
    "def show_images_predicted_as(in_df: pd.DataFrame, pred_label: str, ascending=False, limit=20):\n",
    "    df = in_df[in_df.max_pred==pred_label]\n",
    "    df = df.sort_values(by=pred_label, ascending=ascending)\n",
    "    df = df.reset_index()\n",
    "    print(len(df), 'images found')\n",
    "\n",
    "    columns = 3\n",
    "    plt.figure(figsize=(20,100))\n",
    "    for index, row in df.head(limit).iterrows():\n",
    "        path = row['filename']\n",
    "        im = Image.open(path)\n",
    "        plt.subplot(len(df) / columns + 1, columns, index + 1).set_title(round(row[pred_label],3))\n",
    "        plt.axis('off')\n",
    "        plt.imshow(np.asarray(im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f6c8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('B5_2022-02-07-on-dataset/data-val-epaule_a_percussion_silex-2022-02-14_15:35-probas.csv')\n",
    "show_images_predicted_as(df, 'epaule_a_un_coup')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
